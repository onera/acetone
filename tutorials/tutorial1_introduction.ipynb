{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e705f92",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #1\n",
    "\n",
    "**Generating the code from a given network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc9948",
   "metadata": {},
   "source": [
    "In this notebook, we generate the C code corresponding to a **Acas** neural network, described in two formats: *ONNX* and *NNet*. We then use a random dataset to infere our code and check that the values remain consistent.\n",
    "\n",
    "In the first part of the notebook, we instantiate the main class of ACETONE and use it to generate code.\n",
    "\n",
    "In the second part, we compile the generated code and run it, before comparing the several outputs given by the package.\n",
    "\n",
    "We will show that ACETONE remains consistent regardless of the format of the input.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f15a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check install on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "files_directories = [Path(\"demo_acas_onnx\"), Path(\"demo_acas_nnet\")]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3967d85-b2b1-44da-b6c7-3d56231b88c0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086d179d-d8b4-4cc9-93e8-124cb67d4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import onnxruntime as rt\n",
    "\n",
    "from acetone_nnet import CodeGenerator\n",
    "from acetone_nnet import cli_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997ec04-52bc-4415-a5f8-8d62a7d80d60",
   "metadata": {},
   "source": [
    "## Generating code\n",
    "\n",
    "There is two way to generate the code:\n",
    "* Using the function 'cli_acetone' to directly generate both the output python and the code C\n",
    "* Using the class 'CodeGenerator' to have more controle on the generation\n",
    "\n",
    "The first method is mainly used as a command-line, either by runing the python file, either by using the built in command: *acetone_generate*.\n",
    "Confere to the ReadMe for example using a terminal.\n",
    "The second method is prefered when using the package. \n",
    "It allows more regarding the type of the arguments, give more controle over the generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c28f00",
   "metadata": {},
   "source": [
    "\n",
    "The network we'll use as an exemple here is an ACAS with 6 Dense layer, each separated by a Relu function.\n",
    "\n",
    "![acas](data/acas.png)\n",
    "\n",
    "We'll consider both the [*ONNX*](../tests/models/acas/acas_COC/nn_acas_COC.onnx) and [*NNet*](../tests/models/acas/acas_COC/nn_acas_COC.nnet) format of this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eccf78-bbc4-4772-a7cd-760df2733aca",
   "metadata": {},
   "source": [
    "### Instantiating a **CodeGenerator** element\n",
    "\n",
    "The essential parameter for a **CodeGenerator** element is *model_path*, the path to the model of interest. Some optional parameters can also be given to personalize the generated code:\n",
    "\n",
    "* *test_dataset* : The set of input we will use to test the generated code (must be of shape __(nb_tests , input_shape)__)\n",
    "* *function_name* : The name of the generated function\n",
    "* *nb_tests* : The number of tests we want to run\n",
    "* *normalize* : A boolean indicating if a normalization operator must be applied (only used for the *NNet* format)\n",
    "* *versions* : A dictionary specifying the implementation for a layer (confer [tutorial #2](./tutorial2_using_variants.ipynb))\n",
    "* *debug_mode* : A string indicating the type of model we want to debug (confer [tutorial #3](./tutorial3_using_debug_mode.ipynb))\n",
    "\n",
    "\n",
    "In this introduction, we only consider the first three optional arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd32dd",
   "metadata": {},
   "source": [
    "The output path argument is later used to specify where the computed output must be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948861d5-e387-4be2-9828-3b8d68fcba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../tests/models/acas/acas_COC/nn_acas_COC.nnet\"\n",
    "\n",
    "test_dataset = rd.default_rng(10).random((1,5), dtype=np.float32)\n",
    "function_name = \"demo_acas\"\n",
    "nb_tests = 1\n",
    "\n",
    "nnet_output_path = \"demo_acas_nnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168b8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model initialization.\n"
     ]
    }
   ],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "nnet_generator = CodeGenerator(file=model_path,\n",
    "                            function_name=function_name,\n",
    "                            test_dataset=test_dataset,\n",
    "                            nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341d78f-4b17-450b-89d5-a7e67b465130",
   "metadata": {},
   "source": [
    "### Generating the C code\n",
    "\n",
    "We use the *generate_c_file* methode to generate the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dfc7f8-f2af-499a-b071-1f0f2b9c42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated function source file.\n",
      "Generated function header file.\n",
      "Generated globalvars .c file.\n",
      "Generated main file.\n",
      "Generated Makefile.\n",
      "Generated testdataset files.\n"
     ]
    }
   ],
   "source": [
    "nnet_generator.generate_c_files(nnet_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae2aef",
   "metadata": {},
   "source": [
    "By looking into the file explorer, we can now see that a few files have been generated in the *demo_acas_nnet* directory (which was created if it did not already exist):\n",
    "\n",
    "* [*global_vars.c*](./demo_acas_nnet/global_vars.c)  : Initialization of model parameters\n",
    "\n",
    "* [*inference.h*](./demo_acas_nnet/inference.h)    : Header declaration of the model parameters and the inference function\n",
    "* [*inference.c*](./demo_acas_nnet/inference.c)    : Definition of the inference function\n",
    "* [*test_dataset.h*](./demo_acas_nnet/test_dataset.h) : Declaration of global prameters (input size, number of test, ...) and of the test inputs\n",
    "* [*test_dataset.c*](./demo_acas_nnet/test_dataset.c) : Initialization of the test inputs\n",
    "* [*main.c*](./demo_acas_nnet/main.c)         : Main function, calls the inference on the input and write the result in a file\n",
    "* [*Makefile*](./demo_acas_nnet/Makefile)       : Makefile to compile the C code\n",
    "\n",
    "The neural network himself if contained in the first three files, while the later 4 provides an example of usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1151d-f895-44f1-b6ec-6d810ff8da52",
   "metadata": {},
   "source": [
    "### Importing the ONNX model\n",
    "\n",
    "We do the same operation as before, but this time with an ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f90efa-aa38-4ac4-9e9d-2dc7c5fd3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model initialization.\n",
      "Generated function source file.\n",
      "Generated function header file.\n",
      "Generated globalvars .c file.\n",
      "Generated main file.\n",
      "Generated Makefile.\n",
      "Generated testdataset files.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../tests/models/acas/acas_COC/nn_acas_COC.onnx\"\n",
    "onnx_output_path = \"demo_acas_onnx\"\n",
    "\n",
    "# Create an ACETONE CodeGenerator from the ONNX model\n",
    "onnx_generator = CodeGenerator(file=model_path,\n",
    "                                function_name=function_name,\n",
    "                                test_dataset=test_dataset,\n",
    "                                nb_tests=nb_tests)\n",
    "\n",
    "onnx_generator.generate_c_files(onnx_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb5e1d",
   "metadata": {},
   "source": [
    "## Generating the Python output\n",
    "\n",
    "Now that we have our code, we use the *compute_inference* methode to compute a first evaluation off the inference function on the inputs, using ACETONE's python implementation of the layers. This computation method is used as a reference for the user, to check that the implemented C code returns consistent values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e6c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output_python.txt generated.\n",
      "[24715.65515468 24798.92444016 24650.51800126 24824.74409792\n",
      " 24628.39230361]\n"
     ]
    }
   ],
   "source": [
    "# Computing the inference for the nnet model\n",
    "nnet_output = nnet_generator.compute_inference(nnet_output_path)\n",
    "print(nnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d438cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output_python.txt generated.\n",
      "[24715.65599478 24798.92431218 24650.51894056 24824.74374942\n",
      " 24628.39156172]\n"
     ]
    }
   ],
   "source": [
    "# Computing the inference for the onnx model\n",
    "onnx_output = onnx_generator.compute_inference(onnx_output_path)\n",
    "print(onnx_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d49ef",
   "metadata": {},
   "source": [
    "## Compiling and running the generated code\n",
    "\n",
    "Once the code has been generated, and the first inference has been done, the only remaining step is to compile and run the C code. And that's what the Makefile's `all` command is there for !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5d7fc6-0d9b-47d4-a518-92a1f1ddae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make : on entre dans le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_acas_nnet »\n",
      "gcc  -g -w -lm   -c -o inference.o inference.c\n",
      "gcc  -g -w -lm   -c -o global_vars.o global_vars.c\n",
      "gcc  -g -w -lm   -c -o main.o main.c\n",
      "gcc  -g -w -lm   -c -o test_dataset.o test_dataset.c\n",
      "gcc   -o demo_acas inference.o global_vars.o main.o test_dataset.o  inference.h test_dataset.h   -g -w -lm\n",
      "make : on quitte le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_acas_nnet »\n"
     ]
    }
   ],
   "source": [
    "# Compiling the files\n",
    "! make -C demo_acas_nnet all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8f2f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "⚠️ When running the executable file, do not forget to add as parameter the path to the text file in which the ouptut will be written.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a57c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average time over 1 tests: 9.800000e-07 s \n",
      "   ACETONE framework's inference output: \n",
      "24715.6562 24798.9219 24650.5176 24824.7441 24628.3906 \n"
     ]
    }
   ],
   "source": [
    "# Running the executable\n",
    "! ./demo_acas_nnet/demo_acas ./demo_acas_nnet/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b54a82",
   "metadata": {},
   "source": [
    "Similary, we compile and run the code from the onnx model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e78b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make : on entre dans le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_acas_onnx »\n",
      "gcc  -g -w -lm   -c -o inference.o inference.c\n",
      "gcc  -g -w -lm   -c -o global_vars.o global_vars.c\n",
      "gcc  -g -w -lm   -c -o main.o main.c\n",
      "gcc  -g -w -lm   -c -o test_dataset.o test_dataset.c\n",
      "gcc   -o demo_acas inference.o global_vars.o main.o test_dataset.o  inference.h test_dataset.h   -g -w -lm\n",
      "make : on quitte le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_acas_onnx »\n"
     ]
    }
   ],
   "source": [
    "! make -C demo_acas_onnx all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339d505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average time over 1 tests: 1.020000e-06 s \n",
      "   ACETONE framework's inference output: \n",
      "24715.6562 24798.9219 24650.5176 24824.7441 24628.3906 \n"
     ]
    }
   ],
   "source": [
    "! ./demo_acas_onnx/demo_acas ./demo_acas_onnx/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105f7c4",
   "metadata": {},
   "source": [
    "## Comparing two ouptuts\n",
    "\n",
    "To verify if the two code did give the same value, we use the function *cli_compare*.\n",
    "\n",
    "This command takes as input the path to two ouptut files (C or python) and the number of test done (here 1), and compare them term to term, returning the maximum absolute and relative errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f036786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max absolute error for 1 test(s): 0.001953125\n",
      "    Max relative error for 1 test(s): 7.930380144358296e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing the C and python ouptuts computing from the NNet format\n",
    "cli_compare(\"./demo_acas_nnet/output_python.txt\", \"./demo_acas_nnet/output_c.txt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35ec2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max absolute error for 1 test(s): 0.001953125\n",
      "    Max relative error for 1 test(s): 7.923260998714371e-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing the C and python ouptuts computing from the ONNX format\n",
    "cli_compare(\"./demo_acas_onnx/output_python.txt\", \"./demo_acas_onnx/output_c.txt\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1854acd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max absolute error for 1 test(s): 0.0\n",
      "    Max relative error for 1 test(s): 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing both C ouptuts\n",
    "cli_compare(\"./demo_acas_onnx/output_c.txt\", \"./demo_acas_nnet/output_c.txt\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120e159",
   "metadata": {},
   "source": [
    "Even though the generated coe himself will change to fit the originla network (example: in *ONNX*, the Dense layer is not implemented, thus a combination of a MatMul and an Add are used as a substitute), the output is the same for both networks, demonstrating the robustness of the framework to the input format.\n",
    "\n",
    "The small error between pyhton and c outputs being around `1e-08`, it is considered to be numerical. The values being stored as `float32` is C, and `float64` in Python support that theory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364322b4",
   "metadata": {},
   "source": [
    "## Comparing with *ONNX*\n",
    "\n",
    "We can also use *ONNX*'s official inference package, *onnxruntime*, to get an external reference and validate our models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c99e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result given by onnxruntime : [24715.654 24798.924 24650.518 24824.742 24628.39 ]\n",
      "Result given by ACETONE : [24715.65599478 24798.92431218 24650.51894056 24824.74374942\n",
      " 24628.39156172]\n",
      "Maximal absolute error between them :  0.0016979024876491167\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../tests/models/acas/acas_COC/nn_acas_COC.onnx\"\n",
    "\n",
    "# Inferring the model\n",
    "sess = rt.InferenceSession(model_path)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "result = sess.run(None, {input_name: test_dataset[0]})\n",
    "onnx_result = result[0].ravel().flatten()\n",
    "\n",
    "\n",
    "\n",
    "max_error = 0.0\n",
    "for i in range(5):\n",
    "    max_error = max(max_error, abs(onnx_output[i] - onnx_result[i]))\n",
    "\n",
    "print(\"Result given by onnxruntime :\",onnx_result)\n",
    "print(\"Result given by ACETONE :\",onnx_output)\n",
    "print(\"Maximal absolute error between them : \",max_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf6a21",
   "metadata": {},
   "source": [
    "The comparison between *ONNX*'s official inference package and ACETONE's python output gives a similaire result, with a maximal relative error around `1e-8`, showing our closeness to the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a28db-9c44-4947-a077-15e07b05c443",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Delete generated code before generation\n",
    "- Rename the nnet to nnet\n",
    "- Add calls to\n",
    "  - compiler\n",
    "  - run\n",
    "  - compare nnet and onnx outputs in C\n",
    "  - compare nnet and python outputs\n",
    "- Cleanup excess parameters "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
