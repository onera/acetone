{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e705f92",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #1\n",
    "\n",
    "**Generating the code from a given network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc9948",
   "metadata": {},
   "source": [
    "In this notebook, we generate the C code corresponding to a **Acas COC (?)** neural network, described in two formats: *ONNX* and *NNet*. We then use a random dataset (generated by the package) to infere our code and checking that the values remain consistent.\n",
    "\n",
    "In the first part of the notebook, we instantiate the main class of ACETONE and use it to generate code.\n",
    "\n",
    "In the second part, we compile the generated code and run it, before comparing the several outputs given by the package.\n",
    "\n",
    "We will show that ACETONE remains consistent regardless of the format of the input.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check install on collab\n",
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install git+https://github.com/onera/acetone.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "files_directories = [Path(\"demo_acas_onnx\"), Path(\"demo_acas_nnet\")]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3967d85-b2b1-44da-b6c7-3d56231b88c0",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Only one import is needed for a basic usage of ACETONE: the **CodeGenerator** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d179d-d8b4-4cc9-93e8-124cb67d4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acetone_nnet import CodeGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5a29e",
   "metadata": {},
   "source": [
    "This class implements a local traduction of the neural networkof interest, storing the layers, architectures and parameters of the network. Moreover, the class implements a python inference, with a definite (given or randomly generated) set of inputs, offering a reference against which the C code can be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997ec04-52bc-4415-a5f8-8d62a7d80d60",
   "metadata": {},
   "source": [
    "## Generating code\n",
    "\n",
    "The network we'll use as an exemple if an ACAS with 6 Dense layer, each separated by a Relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Image of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eccf78-bbc4-4772-a7cd-760df2733aca",
   "metadata": {},
   "source": [
    "### Instantiating a **CodeGenerator** element\n",
    "\n",
    "One parameter is truly vital for a **CodeGenerator** element: *model_path*, the path to the model of interest.\n",
    "\n",
    "Other parameters can be given to personalize the generated code, such as the name of the generated function, or the number of the number of datasets on which we are going to perform inference.\n",
    "\n",
    "Finally, the last parameter to set up is the path to the directory in which the code will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948861d5-e387-4be2-9828-3b8d68fcba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../tests/models/acas/acas_COC/nn_acas_COC.nnet\"\n",
    "\n",
    "function_name = \"demo_acas\"\n",
    "nb_tests = 1\n",
    "\n",
    "nnet_output_path = \"demo_acas_nnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "generator = CodeGenerator(file=model_path,\n",
    "                            function_name=function_name,\n",
    "                            nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341d78f-4b17-450b-89d5-a7e67b465130",
   "metadata": {},
   "source": [
    "### Generating the C code\n",
    "\n",
    "We use the *generate_c_file* methode for generating the code. This methode create, in the directory *output_path*, several files containing elements of the code:\n",
    "\n",
    "* *global_vars.c*  : Initialization of model parameters\n",
    "\n",
    "* *inference.h*    : Header declaration of the model parameters and the inference function\n",
    "* *inference.c*    : Definition of the inference function\n",
    "* *test_dataset.h* : Declaration of global prameters (input size, number of test, ...) and of the test inputs\n",
    "* *test_dataset.c* : Initialization of the test inputs\n",
    "* *main.c*         : Main function, calls the inference on the input and write the result in a file\n",
    "* *Makefile*       : Makefile to compile the C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfc7f8-f2af-499a-b071-1f0f2b9c42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.generate_c_files(nnet_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1151d-f895-44f1-b6ec-6d810ff8da52",
   "metadata": {},
   "source": [
    "### Importing the ONNX model\n",
    "\n",
    "We do the same operation as before, but this time with an ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f90efa-aa38-4ac4-9e9d-2dc7c5fd3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../tests/models/acas/acas_COC/nn_acas_COC.onnx\"\n",
    "onnx_output_path = \"demo_acas_onnx\"\n",
    "\n",
    "#\n",
    "onnx_generator = CodeGenerator(file=model_path,\n",
    "                                function_name=function_name,\n",
    "                                nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227c613-829d-4121-bf9f-e10464bcb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_generator.generate_c_files(onnx_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb5e1d",
   "metadata": {},
   "source": [
    "### Generating the Python output\n",
    "\n",
    "We use the *compute_inference* methode to compute a first evaluation off the inference function on the inputs, using ACETONE's python implementation of the layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the inference for the nnet model\n",
    "nnet_output = generator.compute_inference(nnet_output_path)\n",
    "print(nnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d438cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the inference for the onnx model\n",
    "onnx_output = onnx_generator.compute_inference(onnx_output_path)\n",
    "print(onnx_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d49ef",
   "metadata": {},
   "source": [
    "## Compiling and running the generated code\n",
    "\n",
    "Alongside the neural network's code, a main file is generated as a way to run and test the code. The provided Makefile gives the flags to use for the compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d7fc6-0d9b-47d4-a518-92a1f1ddae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make -C demo_acas_nnet all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8f2f4",
   "metadata": {},
   "source": [
    "To run the executable file, add as parameter the path to the text file in which the ouptut will be written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./demo_acas_nnet/demo_acas ./demo_acas_nnet/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b54a82",
   "metadata": {},
   "source": [
    "Similary, we compile and run the code from the onnx model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e78b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make -C demo_acas_onnx all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./demo_acas_onnx/demo_acas ./demo_acas_onnx/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105f7c4",
   "metadata": {},
   "source": [
    "## Comparing two ouptuts\n",
    "\n",
    "To verify if the two code did give the same value, we use the terminal command *acetone_comapre*. Thios command takes as input the path to two ouptut files (C or python) and the number of test done (here 1), and compare them term to term, returning both the max absolute error and the max relative error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f036786",
   "metadata": {},
   "outputs": [],
   "source": [
    "! acetone_compare ./demo_acas_nnet/output_python.txt ./demo_acas_nnet/output_c.txt 1 --precision=float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! acetone_compare ./demo_acas_onnx/output_c.txt ./demo_acas_nnet/output_c.txt 1 --precision=float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ec2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! acetone_compare ./demo_acas_nnet/output_python.txt ./demo_acas_onnx/output_python.txt 1 --precision=float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a28db-9c44-4947-a077-15e07b05c443",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Delete generated code before generation\n",
    "- Rename the nnet to nnet\n",
    "- Add calls to\n",
    "  - compiler\n",
    "  - run\n",
    "  - compare nnet and onnx outputs in C\n",
    "  - compare nnet and python outputs\n",
    "- Cleanup excess parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fd754",
   "metadata": {},
   "source": [
    "There is two way to generate the code:\n",
    "    -Using the function 'cli_acetone' to directly generate both the output python and the code C\n",
    "    -Using the class 'CodeGenerator' to have more controle on the generation\n",
    "\n",
    "This method is mainly used as a command-line, either by runing the python file, either by using the built in command: acetone_generate.\n",
    "Confere to the ReadMe for example using a terminal.\n",
    "This method is prefered when using the package. \n",
    "It allows more regarding the type of the arguments, give more controle over the generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
