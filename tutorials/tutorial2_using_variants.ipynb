{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #2\n",
    "\n",
    "**Implementing and using other versions of a layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency is a key aspect in the embedded sector, with each code being specifically adpated to a terget. As such, we need to be able to chose the implementation of each layer.\n",
    "\n",
    "In this notebook, we'll explain how to create and use specific versions of a layer in ACETONE.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:37:58.837484Z",
     "start_time": "2025-05-07T15:37:58.833771Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Installs on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:37:58.954281Z",
     "start_time": "2025-05-07T15:37:58.881064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "\n",
    "def clean_working_directory(directories):\n",
    "    for directory in directories:\n",
    "        if directory.exists():\n",
    "            for file in listdir(directory):\n",
    "                if not (directory / file).is_dir():\n",
    "                    remove(directory / file)\n",
    "\n",
    "# Path to the example files\n",
    "PATH_DIR = Path(\"../tests/models/lenet5/lenet5_trained\")\n",
    "\n",
    "# Path to generated directories\n",
    "loops_output_path = Path(\"demo_lenet_6loops\")\n",
    "indirect_gemm_output_path = Path(\"demo_lenet_indirect_gemm\")\n",
    "std_gemm_output_path = Path(\"demo_lenet_std_gemm\")\n",
    "demo_output_path = Path(\"demo_lenet_optimized\")\n",
    "\n",
    "files_directories = [loops_output_path, indirect_gemm_output_path, std_gemm_output_path, demo_output_path]\n",
    "\n",
    "clean_working_directory(files_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as an example a simple Lenet5 model exported to Keras' format h5. The used dataset is randomly generated for testing purposes.\n",
    "\n",
    "![lenet5](./data/lenet5_trained.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:19.809270Z",
     "start_time": "2025-05-07T15:38:00.550230Z"
    }
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import numpy as np\n",
    "import pystache\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "# ACETONE's imports\n",
    "from acetone_nnet import CodeGenerator, cli_compare, list_all_implementations, conv2d_factory\n",
    "from acetone_nnet.generator import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few useful functions\n",
    "\n",
    "We define two functions, one to write a set of inputs into an text file and the other to extract the C code's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_input(inputs, nb_tests, file_name):\n",
    "    \"\"\"Writes a list of inputs in a text file.\n",
    "\n",
    "    Args:\n",
    "        inputs (list[np.ndarray]): The list of inputs to write\n",
    "        nb_tests (int): The number of inputs\n",
    "        file_name (str | Path): The path to the file in which the inputs will be written\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Can't write more tests (nb_tests) than the number of given inputs\n",
    "    \"\"\"\n",
    "    if nb_tests > len(inputs):\n",
    "        raise ValueError(f\"Can't have more tests to write ({nb_tests}) than values ({len(inputs)})\")\n",
    "    with open(file_name, \"w+\") as fi:\n",
    "        for i in range(nb_tests):\n",
    "            x = inputs[i].flatten()\n",
    "            out_string = \" \".join(\n",
    "                [f'{float(n).hex().replace(\"0000000p\", \"p\")}' for n in x],\n",
    "            )\n",
    "            print(f\"{out_string}\", file=fi, flush=True)\n",
    "\n",
    "\n",
    "def extract_outputs_c(\n",
    "        path_to_output: str | Path,\n",
    "        nb_tests: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Get the outputs values from the txt file.\"\"\"\n",
    "    output = []\n",
    "    with Path.open(Path(path_to_output)) as f:\n",
    "        for i, line in enumerate(f):\n",
    "\n",
    "            line = line[:-2].split(\" \")\n",
    "            line = list(map(float.fromhex, line))\n",
    "            line = np.array(line)\n",
    "            \n",
    "            output.append(line)\n",
    "            \n",
    "            if i >= nb_tests:\n",
    "                break\n",
    "    f.close()\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images\n",
    "\n",
    "We first load MNIST data from keras dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "y_train = keras.utils.to_categorical(y_train_)\n",
    "y_test = keras.utils.to_categorical(y_test_)\n",
    "\n",
    "x_train = np.array([x.reshape((28,28)) for x in x_train])\n",
    "x_test = np.array([x.reshape((28,28)) for x in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a test input\n",
    "\n",
    "We select a few random images to use as support for the later parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_col = 5\n",
    "nb_row = 2\n",
    "nb_samples = nb_col*nb_row\n",
    "indexes = np.random.permutation(len(x_test))[:nb_samples]\n",
    "\n",
    "inputs = x_test[indexes]\n",
    "\n",
    "fig,axs = plt.subplots(nb_row,nb_col)\n",
    "\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(inputs[i*nb_col+j], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining common parameters and training the model\n",
    "\n",
    "We then prepare the CodeGenerator's initialization parameters and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:19.828012Z",
     "start_time": "2025-05-07T15:38:19.824633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the model\n",
    "model_path = PATH_DIR / \"lenet5_trained.h5\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "# Path to the input file\n",
    "dataset = Path(\"./lenet_inputs.txt\")\n",
    "write_input(inputs, nb_samples, dataset)\n",
    "# Function name\n",
    "function_name = \"demo_lenet\"\n",
    "# Number of test\n",
    "nb_tests = nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, shuffle=True, validation_split=0.2, epochs=3)\n",
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of `0.98`, which means that out of 100 images, 98 will be well labeled. we will now generate the C code while preserving its semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ACETONE's native implementations\n",
    "\n",
    "The framework laready provides, for some layers, several versions from which to choose before generating our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:19.893377Z",
     "start_time": "2025-05-07T15:38:19.887072Z"
    }
   },
   "outputs": [],
   "source": [
    "implemented = list_all_implementations()\n",
    "for layer_name in implemented:\n",
    "    print(layer_name,\":\")\n",
    "    for implementation in implemented[layer_name]:\n",
    "        print(\"   \", implementation)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version of the layer to use\n",
    "conv_algorithm = \"indirect_gemm_nn\"\n",
    "\n",
    "# Create an ACETONE CodeGenerator from the model\n",
    "\n",
    "Let's focus on the convolution layer.\n",
    "\n",
    "The 3 main algorithms provided by ACETONE for the convolution are: *6loops*, *std_gemm* and *indirect_gemm*.\n",
    "\n",
    "The first algorithm implements the naive version of a convolution: a triple loop iters all the indices of the ouput, and for each of this indices another triple loop compute the value using the input tensor and the kernel, as illustrated below (for a 2D exemple).\n",
    "\n",
    "![Conv_6loops](./data/conv_6loops.gif \"segment\")\n",
    "\n",
    "We can change the implementation of a specific type of layer by using the class **CodeGenerator**'s argument `versions`.\n",
    "This argument takes a dictionary containing a reference to the layer (usually the name) as key and the version's name as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:24.273242Z",
     "start_time": "2025-05-07T15:38:20.065867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "loops_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"6loops\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:24.962517Z",
     "start_time": "2025-05-07T15:38:24.292506Z"
    }
   },
   "outputs": [],
   "source": [
    "loops_generator.generate_c_files(loops_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm, *std_gemm*, uses the standard gemm (as the name suggests) to compute the convolution. In the generated C code, the convolution is divided in two main parts: the creation of the matrix of patches from the input then the multiplication of the resulting matrix with the kernel matrix.\n",
    "\n",
    "![Conv_std_gemm](./data/std_gemm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:25.071575Z",
     "start_time": "2025-05-07T15:38:24.980367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "std_gemm_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"std_gemm_nn\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:25.306050Z",
     "start_time": "2025-05-07T15:38:25.096800Z"
    }
   },
   "outputs": [],
   "source": [
    "std_gemm_generator.generate_c_files(std_gemm_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third algorithm is another implementation of the gemm algorithm. Instead of computing the patches matrix during the execution inf the C code, the framework computes before the generation and add to the code a matrix of pointers, each refering to the corresponding element in the input tensor.\n",
    "\n",
    "![Conv_indirect_gemm](./data/indirect_gemm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:25.403163Z",
     "start_time": "2025-05-07T15:38:25.321212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "indirect_gemm_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"indirect_gemm_nn\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:25.613299Z",
     "start_time": "2025-05-07T15:38:25.422040Z"
    }
   },
   "outputs": [],
   "source": [
    "indirect_gemm_generator.generate_c_files(indirect_gemm_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile and run those generated code to ensure that the semantic was indeed preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_6loops all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_6loops/demo_lenet ./demo_lenet_6loops/output_c.txt ./lenet_inputs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:28.534090Z",
     "start_time": "2025-05-07T15:38:27.802796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_std_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_std_gemm/demo_lenet ./demo_lenet_std_gemm/output_c.txt ./lenet_inputs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:27.685038Z",
     "start_time": "2025-05-07T15:38:25.628813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_indirect_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_indirect_gemm/demo_lenet ./demo_lenet_indirect_gemm/output_c.txt ./lenet_inputs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:28.553668Z",
     "start_time": "2025-05-07T15:38:28.548815Z"
    }
   },
   "outputs": [],
   "source": [
    "cli_compare(reference_file=(indirect_gemm_output_path / \"output_c.txt\"), c_file=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops_output = extract_outputs_c(path_to_output=(loops_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "std_gemm_output = extract_outputs_c(path_to_output=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "indirect_gemm_output = extract_outputs_c(path_to_output=(indirect_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "\n",
    "loops_labels = loops_output.argmax(axis = -1)\n",
    "std_gemm_labels = std_gemm_output.argmax(axis = -1)\n",
    "indirect_gemm_labels = indirect_gemm_output.argmax(axis = -1)\n",
    "\n",
    "\n",
    "print(\"Labels given by the inference:\")\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        print(f\"sample at position ({i},{j}) : \")\n",
    "        print(f\"    6loops :        {loops_labels[i*nb_col + j]}\")\n",
    "        print(f\"    std_gemm :      {std_gemm_labels[i*nb_col + j]}\")\n",
    "        print(f\"    indirect_gemm : {indirect_gemm_labels[i*nb_col + j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated code gives indeed the same label for all the implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new implementation\n",
    "\n",
    "Let's now assume that, after studies and tests, we have found a new way to perform a convolution : setting each element of the output to `0.42`.\n",
    "\n",
    "This method being far more efficient and simple than any other, we want to use it with ACETONE. But, sadly, the framework doesn't have an implementation for it, we have to add it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:28.607392Z",
     "start_time": "2025-05-07T15:38:28.603513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Printing all the algorithm implemented in ACETONE for a convolution\n",
    "print(\"Base implementations : \")\n",
    "print(conv2d_factory.list_implementations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement it, we have to  create a new class inheriting from the `Conv2D` class (or one of its child classes). \n",
    "\n",
    "* The first method we must implement is called `generate_inference_code`. This method will construct the C code correponding to the layer, and return it as a string.\n",
    "* The second method, `forwad_path_layer`, is optional. It tell the framework how to compute the output of the layer unsing Pyhton. If not given, the method defined in the parent class is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:28.667631Z",
     "start_time": "2025-05-07T15:38:28.659150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a new implementation\n",
    "class Conv2D_Demo(Conv2D):\n",
    "\n",
    "    def __init__(self, **kwargs: int) -> None:\n",
    "        \"\"\"Build a Convolution layer with a demo implementation.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def generate_inference_code_layer(self) -> str:\n",
    "        \"\"\"Generate computation code for layer.\"\"\"\n",
    "        input_str = [prev_layer.output_str for prev_layer in self.previous_layer]\n",
    "        ouptut_str = f\"output_{self.path}\"\n",
    "\n",
    "        code_str =  \"    // {{name}}_{{idx}}\\n    for (k = 0; k < {{size}}; ++k) {{output_str}}[k] = 0.42;\"\n",
    "        return pystache.render(code_str,{\"name\":self.name, \"idx\":self.idx, \"size\":self.size,\"output_str\":ouptut_str})\n",
    "    \n",
    "    def forward_path_layer(self, input_array) -> np.ndarray:\n",
    "        return 0.42*np.ones((1,self.output_channels,self.output_height,self.output_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parsing the neural network, each time ACETONE encounters a layer having several versions, it places a temporary layers. Once the model completly extracted, those placeholders are then replaced by a defintive layer whith the correct implementation, simply by extracting the values stored (such as weight, size, biases, ...) and using them to initialize a new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Conv2D_Demo layer using the attributes of old_layer\n",
    "def conv2d_demo_implementation(\n",
    "        old_layer: Conv2D,\n",
    "        conv_algo: str,\n",
    ") -> Conv2D_Demo:\n",
    "    return Conv2D_Demo(\n",
    "        idx=old_layer.idx,\n",
    "        conv_algorithm=conv_algo,\n",
    "        size=old_layer.size,\n",
    "        padding=old_layer.padding,\n",
    "        strides=old_layer.strides,\n",
    "        kernel_h=old_layer.kernel_h,\n",
    "        kernel_w=old_layer.kernel_w,\n",
    "        dilation_rate=old_layer.dilation_rate,\n",
    "        nb_filters=old_layer.nb_filters,\n",
    "        input_shape=[1, old_layer.input_channels, old_layer.input_height, old_layer.input_width],\n",
    "        output_shape=[1, old_layer.output_channels, old_layer.output_height, old_layer.output_width],\n",
    "        weights=old_layer.weights,\n",
    "        biases=old_layer.biases,\n",
    "        activation_function=old_layer.activation_function,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to add the newly created implementation to ACETONE, we need to register it within the layer's version manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:28.816766Z",
     "start_time": "2025-05-07T15:38:28.813270Z"
    }
   },
   "outputs": [],
   "source": [
    "conv2d_factory.register_implementation(\"demo\", conv2d_demo_implementation)\n",
    "\n",
    "print(\"Updated implementations : \")\n",
    "print(conv2d_factory.list_implementations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new version being available in the list of implementations, we can now use it to generate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:38:29.016174Z",
     "start_time": "2025-05-07T15:38:28.869992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "demo_generator = CodeGenerator(file=model,\n",
    "                                    function_name=function_name,\n",
    "                                    external_input=True,\n",
    "                                    versions={\"Conv2D\":\"demo\"},\n",
    "                                    nb_tests=nb_tests,\n",
    "                                    verbose=False)\n",
    "\n",
    "demo_generator.generate_c_files(demo_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code then has the optimized implementation and is ready to be deployed on any target !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Case\n",
    "\n",
    "Comparing the outputs of a random dataset is great for tests, but not really demonstratif and adapted to a tutorial like this one. \n",
    "\n",
    "To illustrate the conservation of semantics between the different versions seen, we'll use the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a bit more\n",
    "\n",
    "Let's now try with several set of inputs from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting new inputs\n",
    "indexes = np.random.permutation(len(x_test))[:nb_samples]\n",
    "inputs = x_test[indexes]\n",
    "write_input(inputs, nb_samples, dataset)\n",
    "\n",
    "# Keras inference and labels\n",
    "keras_ouputs = model.predict(inputs)\n",
    "keras_labels = keras_ouputs.argmax(axis=-1)\n",
    "\n",
    "# ACETONE's inference with the 3 versions\n",
    "! ./demo_lenet_6loops/demo_lenet ./demo_lenet_6loops/output_c.txt ./lenet_inputs.txt\n",
    "! ./demo_lenet_std_gemm/demo_lenet ./demo_lenet_std_gemm/output_c.txt ./lenet_inputs.txt\n",
    "! ./demo_lenet_indirect_gemm/demo_lenet ./demo_lenet_indirect_gemm/output_c.txt ./lenet_inputs.txt\n",
    "\n",
    "# Extracting the scores\n",
    "loops_output = extract_outputs_c(path_to_output=(loops_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "std_gemm_output = extract_outputs_c(path_to_output=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "indirect_gemm_output = extract_outputs_c(path_to_output=(indirect_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "\n",
    "# Getting the labels\n",
    "loops_labels = loops_output.argmax(axis = -1)\n",
    "std_gemm_labels = std_gemm_output.argmax(axis = -1)\n",
    "indirect_gemm_labels = indirect_gemm_output.argmax(axis = -1)\n",
    "\n",
    "fig,axs = plt.subplots(nb_row,nb_col)\n",
    "fig.suptitle(\"Label given by : Keras-6loops-std_gemm-indirect_gemm\")\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(inputs[i*nb_col+j], cmap=\"gray\")\n",
    "        ax.set_title(f\"{keras_labels[i*nb_col+j]}-{loops_labels[i*nb_col+j]}-{std_gemm_labels[i*nb_col+j]}-{indirect_gemm_labels[i*nb_col+j]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four labels are the same, the semantic is preserved !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
