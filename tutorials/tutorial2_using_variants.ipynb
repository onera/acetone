{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Tuto for using / implementing a variant in ACETONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #2\n",
    "\n",
    "**Implementing and using other versions of a layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency is a key aspect in the embedded sector, with each code being specifically adpated to a terget. As such, we need to be able to chose the implementation of each layer.\n",
    "\n",
    "In this notebook, we'll explain how to create and use specific versions of a layer in ACETONE.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Installs on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "files_directories = [Path(\"demo_lenet_indirect_gemm\"),Path(\"demo_lenet_std_gemm\"), Path(\"demo_lenet_easy\")]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as an example a simple Lenet5 model exported to Keras' format h5. The used dataset is randomly generated for testing purposes.\n",
    "\n",
    "![lenet5](./data/lenet5_trained.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from acetone_nnet import CodeGenerator, cli_compare, list_all_implementations, conv2d_factory\n",
    "from acetone_nnet.generator import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../tests/models/lenet5/lenet5_trained/lenet5_trained.h5\"\n",
    "test_dataset = \"../tests/models/lenet5/lenet5_trained/test_input_lenet5.txt\"\n",
    "function_name = \"demo_lenet\"\n",
    "nb_tests = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ACETONE's native implementations\n",
    "\n",
    "The framework laready provides, for some layers, several versions from which to choose before generating our code. \n",
    "In this notebook, we will focus on the convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D :\n",
      "    6loops\n",
      "    indirect_gemm_nn\n",
      "    indirect_gemm_tn\n",
      "    indirect_gemm_nt\n",
      "    indirect_gemm_tt\n",
      "    std_gemm_nn\n",
      "    std_gemm_tn\n",
      "    std_gemm_nt\n",
      "    std_gemm_tt\n",
      "    gemm_target\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "implemented = list_all_implementations()\n",
    "for layer_name in implemented:\n",
    "    print(layer_name,\":\")\n",
    "    for implementation in implemented[layer_name]:\n",
    "        print(\"   \", implementation)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the implementation of a specific type of layer by using the class **CodeGenerator**'s argument `versions`. \n",
    "\n",
    "This argument takes a dictionnary containing a reference to the layer (usually the name) as key and the verion's name as value.\n",
    "\n",
    "In this example, we want to use the algorithm `indirect_gemm_nn` to compute the convolution. ***(Describe algo)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 15:34:04.001850: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 15:34:04.059831: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 15:34:04.060487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-11 15:34:05.476595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Finished model initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 15:34:08.240235: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Version of the layer to use\n",
    "conv_algorithm = \"indirect_gemm_nn\"\n",
    "indirect_gemm_output_path = \"demo_lenet_indirect_gemm\"\n",
    "\n",
    "# Create an ACETONE CodeGenerator from the model\n",
    "indirect_gemm_generator = CodeGenerator(file=model_path,\n",
    "                                            function_name=function_name,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            versions={\"Conv2D\":conv_algorithm},\n",
    "                                            nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the generator has been created, we can generate the corresponding C code and compute the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated function source file.\n",
      "Generated function header file.\n",
      "Conv2D 1 patches size: (14400,)\n",
      "Conv2D 3 patches size: (9600,)\n",
      "Generated globalvars .c file.\n",
      "Generated main file.\n",
      "Generated Makefile.\n",
      "Generated testdataset files.\n",
      "(1, 5, 5, 6)\n",
      "(6, 5, 5, 16)\n",
      "File output_python.txt generated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.14688426e-05, 9.42424937e-09, 2.48964154e-03, 9.30244851e-01,\n",
       "       4.02413366e-09, 4.87522280e-07, 1.02479293e-09, 2.22011113e-08,\n",
       "       6.72312127e-02, 1.23013641e-05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indirect_gemm_generator.generate_c_files(indirect_gemm_output_path)\n",
    "indirect_gemm_generator.compute_inference(indirect_gemm_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Finished model initialization.\n"
     ]
    }
   ],
   "source": [
    "# Version of the layer to use\n",
    "conv_algorithm = \"std_gemm_nn\"\n",
    "std_gemm_output_path = \"demo_lenet_std_gemm\"\n",
    "\n",
    "# Create an ACETONE CodeGenerator from the model\n",
    "std_gemm_generator = CodeGenerator(file=model_path,\n",
    "                                    function_name=function_name,\n",
    "                                    test_dataset=test_dataset,\n",
    "                                    versions={1:conv_algorithm, 3:conv_algorithm},\n",
    "                                    nb_tests=nb_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated function source file.\n",
      "Generated function header file.\n",
      "Generated globalvars .c file.\n",
      "Generated main file.\n",
      "Generated Makefile.\n",
      "Generated testdataset files.\n",
      "(1, 5, 5, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 5, 16)\n",
      "File output_python.txt generated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.14688426e-05, 9.42424937e-09, 2.48964154e-03, 9.30244851e-01,\n",
       "       4.02413366e-09, 4.87522280e-07, 1.02479293e-09, 2.22011113e-08,\n",
       "       6.72312127e-02, 1.23013641e-05])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_gemm_generator.generate_c_files(std_gemm_output_path)\n",
    "std_gemm_generator.compute_inference(std_gemm_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make : on entre dans le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_lenet_indirect_gemm »\n",
      "gcc  -g -w -lm   -c -o inference.o inference.c\n",
      "gcc  -g -w -lm   -c -o global_vars.o global_vars.c\n",
      "gcc  -g -w -lm   -c -o main.o main.c\n",
      "gcc  -g -w -lm   -c -o test_dataset.o test_dataset.c\n",
      "gcc   -o demo_lenet inference.o global_vars.o main.o test_dataset.o  inference.h test_dataset.h   -g -w -lm\n",
      "make : on quitte le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_lenet_indirect_gemm »\n",
      "   Average time over 1 tests: 1.155000e-05 s \n",
      "   ACETONE framework's inference output: \n",
      "2.14688262e-05 9.42424627e-09 0.00248963805 0.930245101 4.02412859e-09 4.8752247e-07 1.02479236e-09 2.22010641e-08 0.0672310665 1.23013542e-05 \n"
     ]
    }
   ],
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_indirect_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_indirect_gemm/demo_lenet ./demo_lenet_indirect_gemm/output_c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make : on entre dans le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_lenet_std_gemm »\n",
      "gcc  -g -w -lm   -c -o inference.o inference.c\n",
      "gcc  -g -w -lm   -c -o global_vars.o global_vars.c\n",
      "gcc  -g -w -lm   -c -o main.o main.c\n",
      "gcc  -g -w -lm   -c -o test_dataset.o test_dataset.c\n",
      "gcc   -o demo_lenet inference.o global_vars.o main.o test_dataset.o  inference.h test_dataset.h   -g -w -lm\n",
      "make : on quitte le répertoire « /tmp_user/ldtim610h/yaitaiss/acetone/tutorials/demo_lenet_std_gemm »\n",
      "   Average time over 1 tests: 1.263000e-05 s \n",
      "   ACETONE framework's inference output: \n",
      "2.14688262e-05 9.42424627e-09 0.00248963805 0.930245101 4.02412859e-09 4.8752247e-07 1.02479236e-09 2.22010641e-08 0.0672310665 1.23013542e-05 \n"
     ]
    }
   ],
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_std_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_std_gemm/demo_lenet ./demo_lenet_std_gemm/output_c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max absolute error for 1 test(s): 0.0\n",
      "    Max relative error for 1 test(s): 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cli_compare(reference_file=\"./demo_lenet_indirect_gemm/output_c.txt\", c_file=\"./demo_lenet_std_gemm/output_c.txt\", nb_tests=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new implementation\n",
    "\n",
    "Let's now assume that, after studies and tests, we have found a new way to perform a convolution : setting each element of the output to `0.42`.\n",
    "\n",
    "This method being far more efficient and simple than any other, we want to use it with ACETONE. But, sadly, the framework doesn't have an implementation for it, we have to add it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base implementations : \n",
      "['6loops', 'indirect_gemm_nn', 'indirect_gemm_tn', 'indirect_gemm_nt', 'indirect_gemm_tt', 'std_gemm_nn', 'std_gemm_tn', 'std_gemm_nt', 'std_gemm_tt', 'gemm_target']\n"
     ]
    }
   ],
   "source": [
    "# Printing all the algorithm implemented in ACETONE for a convolution\n",
    "print(\"Base implementations : \")\n",
    "print(conv2d_factory.list_implementations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement it, we have to  create a new class inheriting from the `Conv2D` class (or one of its child classes). \n",
    "\n",
    "* The first method we must implement is called `generate_inference_code`. This method will construct the C code correponding to the layer, and return it as a string.\n",
    "* The second method, `forwad_path_layer`, is optional. It tell the framework how to compute the output of the layer unsing Pyhton. If not given, the method defined in the parent class is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new implementation\n",
    "class Conv2D_Demo(Conv2D):\n",
    "\n",
    "    def __init__(self, **kwargs: int) -> None:\n",
    "        \"\"\"Build a Convolution layer with a demo implementation.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def generate_inference_code_layer(self) -> str:\n",
    "        \"\"\"Generate computation code for layer.\"\"\"\n",
    "        input_str = [prev_layer.output_str for prev_layer in self.previous_layer]\n",
    "        ouptut_str = f\"output_{self.path}\"\n",
    "\n",
    "        code_str =  f\"    // {self.name}_{self.idx}\\n    for (k = 0; k < {self.size}; ++k) {ouptut_str}[k] = 0.42;\"\n",
    "        return code_str\n",
    "    \n",
    "    def forward_path_layer(self, input_array) -> np.ndarray:\n",
    "        return 0.42*np.ones((1,self.output_channels,self.output_height,self.output_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When parsing the neural network, each time ACETONE encounters a layer having several versions, it places a temporary layers. Once the model completly extracted, those placeholders are then replaced by a defintive layer whith the correct implementation, simply by extracting the values stored (such as weight, size, biases, ...) and using them to initialize a new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Conv2D_Demo layer using the attributes of old_layer\n",
    "def conv2d_demo_implementation(\n",
    "        old_layer: Conv2D,\n",
    "        conv_algo: str,\n",
    ") -> Conv2D_Demo:\n",
    "    return Conv2D_Demo(\n",
    "        idx=old_layer.idx,\n",
    "        conv_algorithm=conv_algo,\n",
    "        size=old_layer.size,\n",
    "        padding=old_layer.padding,\n",
    "        strides=old_layer.strides,\n",
    "        kernel_h=old_layer.kernel_h,\n",
    "        kernel_w=old_layer.kernel_w,\n",
    "        dilation_rate=old_layer.dilation_rate,\n",
    "        nb_filters=old_layer.nb_filters,\n",
    "        input_shape=[1, old_layer.input_channels, old_layer.input_height, old_layer.input_width],\n",
    "        output_shape=[1, old_layer.output_channels, old_layer.output_height, old_layer.output_width],\n",
    "        weights=old_layer.weights,\n",
    "        biases=old_layer.biases,\n",
    "        activation_function=old_layer.activation_function,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to add the newly created implementation to ACETONE, we need to register it within the layer's version manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated implementations : \n",
      "['6loops', 'indirect_gemm_nn', 'indirect_gemm_tn', 'indirect_gemm_nt', 'indirect_gemm_tt', 'std_gemm_nn', 'std_gemm_tn', 'std_gemm_nt', 'std_gemm_tt', 'gemm_target', 'demo']\n"
     ]
    }
   ],
   "source": [
    "conv2d_factory.register_implementation(\"demo\", conv2d_demo_implementation)\n",
    "\n",
    "print(\"Updated implementations : \")\n",
    "print(conv2d_factory.list_implementations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new version being available in the list of implementations, we can now use it to generate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Finished model initialization.\n",
      "Generated function source file.\n",
      "Generated function header file.\n",
      "Generated globalvars .c file.\n",
      "Generated main file.\n",
      "Generated Makefile.\n",
      "Generated testdataset files.\n"
     ]
    }
   ],
   "source": [
    "# Version of the layer to use\n",
    "conv_algorithm = \"demo\"\n",
    "demo_output_path = \"demo_lenet_optimized\"\n",
    "\n",
    "# Create an ACETONE CodeGenerator from the model\n",
    "demo_generator = CodeGenerator(file=model_path,\n",
    "                                    function_name=function_name,\n",
    "                                    test_dataset=test_dataset,\n",
    "                                    versions={\"Conv2D\":conv_algorithm},\n",
    "                                    nb_tests=nb_tests)\n",
    "\n",
    "demo_generator.generate_c_files(demo_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code then has the optimized implementation and is ready to be deployed on any target !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
