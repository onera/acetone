{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #2\n",
    "\n",
    "**Using other versions of a layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency is a key aspect in the embedded sector, with each code being specifically adpated to a target. As such, we need to be able to choose the implementation of each layer.\n",
    "\n",
    "In this notebook, we'll explain how to use specific versions of a layer in ACETONE.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE\n",
    "\n",
    "The Python code on which the code for manipulating data from the MNIST database was originally written by MÃ©lanie Ducoffe for the ANITI Tech'Session about the librairy DECOMON on 4/04/2025 ([replay](https://www.youtube.com/watch?v=1Jhj3xbsF1k&t=8s)). The code can be found in the [tutorial 3](https://airbus.github.io/decomon/main/tutorials.html) about local robustness to adversarial attacks for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO Installs on collab"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "\n",
    "def clean_working_directory(directories):\n",
    "    for directory in directories:\n",
    "        if directory.exists():\n",
    "            for file in listdir(directory):\n",
    "                if not (directory / file).is_dir():\n",
    "                    remove(directory / file)\n",
    "\n",
    "# Path to the example files\n",
    "PATH_DIR = Path(\"../tests/models/lenet5/lenet5_trained\")\n",
    "\n",
    "# Path to generated directories\n",
    "loops_output_path = Path(\"demo_lenet_6loops\")\n",
    "indirect_gemm_output_path = Path(\"demo_lenet_indirect_gemm\")\n",
    "std_gemm_output_path = Path(\"demo_lenet_std_gemm\")\n",
    "demo_output_path = Path(\"demo_lenet_optimized\")\n",
    "\n",
    "files_directories = [loops_output_path, indirect_gemm_output_path, std_gemm_output_path, demo_output_path]\n",
    "\n",
    "clean_working_directory(files_directories)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as an example a simple Lenet5 model exported to Keras' format h5. The first four activation functions are hyperbolic tangents, while the last one is a softmax.\n",
    "\n",
    "![lenet5](./data/lenet5_trained.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# External imports\n",
    "import numpy as np\n",
    "import pystache\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "# ACETONE's imports\n",
    "from acetone_nnet import CodeGenerator, cli_compare, list_all_implementations, conv2d_factory\n",
    "from acetone_nnet.generator import Conv2D"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few useful functions\n",
    "\n",
    "We define two functions, one to write a set of inputs into an text file and the other to extract the C code's outputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def write_input(inputs, nb_tests, file_name):\n",
    "    \"\"\"Writes a list of inputs in a text file.\n",
    "\n",
    "    Args:\n",
    "        inputs (list[np.ndarray]): The list of inputs to write\n",
    "        nb_tests (int): The number of inputs\n",
    "        file_name (str | Path): The path to the file in which the inputs will be written\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Can't write more tests (nb_tests) than the number of given inputs\n",
    "    \"\"\"\n",
    "    if nb_tests > len(inputs):\n",
    "        raise ValueError(f\"Can't have more tests to write ({nb_tests}) than values ({len(inputs)})\")\n",
    "    with open(file_name, \"w+\") as fi:\n",
    "        for i in range(nb_tests):\n",
    "            x = inputs[i].flatten()\n",
    "            out_string = \" \".join(\n",
    "                [f'{float(n).hex().replace(\"0000000p\", \"p\")}' for n in x],\n",
    "            )\n",
    "            print(f\"{out_string}\", file=fi, flush=True)\n",
    "\n",
    "\n",
    "def extract_outputs_c(\n",
    "        path_to_output: str | Path,\n",
    "        nb_tests: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Get the outputs values from the txt file.\"\"\"\n",
    "    output = []\n",
    "    with Path.open(Path(path_to_output)) as f:\n",
    "        for i, line in enumerate(f):\n",
    "\n",
    "            line = line[:-2].split(\" \")\n",
    "            line = list(map(float.fromhex, line))\n",
    "            line = np.array(line)\n",
    "            \n",
    "            output.append(line)\n",
    "            \n",
    "            if i >= nb_tests:\n",
    "                break\n",
    "    f.close()\n",
    "    return np.array(output)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images\n",
    "\n",
    "We first load MNIST data from keras dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train_), (x_test, y_test_) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "y_train = keras.utils.to_categorical(y_train_)\n",
    "y_test = keras.utils.to_categorical(y_test_)\n",
    "\n",
    "x_train = np.array([x.reshape((28,28)) for x in x_train])\n",
    "x_test = np.array([x.reshape((28,28)) for x in x_test])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a test input\n",
    "\n",
    "We select a few random images to use as support for the later parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nb_col = 5\n",
    "nb_row = 2\n",
    "nb_samples = nb_col*nb_row\n",
    "indexes = np.random.permutation(len(x_test))[:nb_samples]\n",
    "\n",
    "inputs = x_test[indexes]\n",
    "\n",
    "fig,axs = plt.subplots(nb_row,nb_col)\n",
    "\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(inputs[i*nb_col+j], cmap=\"gray\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining common parameters and training the model\n",
    "\n",
    "We then prepare the CodeGenerator's initialization parameters and train the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Path to the model\n",
    "model_path = PATH_DIR / \"lenet5_trained.h5\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"acc\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.fit(x_train, y_train, batch_size=32, shuffle=True, validation_split=0.2, epochs=3)\n",
    "model.evaluate(x_test, y_test, batch_size=32)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of `0.98`, which means that out of 100 images, 98 will be well labeled. we will now generate the C code while preserving its semantics.\n",
    "\n",
    "With our test inputs, we have:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Inference\n",
    "keras_outputs = model.predict(inputs)\n",
    "# The index of the highest scores represents the label\n",
    "keras_labels = keras_outputs.argmax(axis=-1)\n",
    "\n",
    "print(f\"The labels are: {keras_labels}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Path to the input file\n",
    "dataset = Path(\"./lenet_inputs.txt\")\n",
    "write_input(inputs, nb_samples, dataset)\n",
    "# Function name\n",
    "function_name = \"demo_lenet\"\n",
    "# Number of tests\n",
    "nb_tests = nb_samples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ACETONE's native implementations\n",
    "\n",
    "The framework laready provides, for some layers, several versions from which to choose before generating our code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "implemented = list_all_implementations()\n",
    "for layer_name in implemented:\n",
    "    print(layer_name,\":\")\n",
    "    for implementation in implemented[layer_name]:\n",
    "        print(\"   \", implementation)\n",
    "    print(\"\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an ACETONE CodeGenerator from the model\n",
    "\n",
    "Let's focus on the convolution layer.\n",
    "\n",
    "The 3 main algorithms provided by ACETONE for the convolution are: *6loops*, *std_gemm* and *indirect_gemm*.\n",
    "\n",
    "The first algorithm implements the naive version of a convolution: a triple loop iters all the indices of the ouput, and for each of this indices another triple loop compute the value using the input tensor and the kernel, as illustrated below (for a 2D example).\n",
    "\n",
    "![Conv_6loops](./data/conv_6loops.gif \"segment\")\n",
    "\n",
    "(Figure excerpt from [https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/](https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/))\n",
    "\n",
    "We can change the implementation of a specific type of layer by using the class **CodeGenerator**'s argument `versions`.\n",
    "This argument takes a dictionary containing a reference to the layer (usually the name) as key and the version's name as value."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "loops_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"6loops\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "loops_generator.generate_c_files(loops_output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm, *std_gemm*, uses the standard gemm (as the name suggests) to compute the convolution. In the generated C code, the convolution is divided in two main parts: the creation of the matrix of patches from the input then the multiplication of the resulting matrix with the kernel matrix.\n",
    "\n",
    "![Conv_std_gemm](./data/std_gemm.png)\n",
    "\n",
    "(Figure excerpt from [*Extending a predictable machine learning framework with efficient gemm-based convolution routines*](https://theses.hal.science/ONERA-MIP/hal-04627347v1) written by Iryna De Albuquerque Silva, Thomas Carle, Adrien Gauffriau and Claire Pagetti)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "std_gemm_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"std_gemm_nn\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "std_gemm_generator.generate_c_files(std_gemm_output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third algorithm is another implementation of the gemm algorithm. Instead of computing the patches matrix during the execution of the C code, the framework computes before the generation and adds to the code a matrix of pointers, each referring to the corresponding element in the input tensor. The `im2col` operation is then included in the pointer matrix instead of being computed during execution.\n",
    "\n",
    "![Conv_indirect_gemm](./data/indirect_gemm.png)\n",
    "\n",
    "(Figure excerpt from [*Extending a predictable machine learning framework with efficient gemm-based convolution routines*](https://theses.hal.science/ONERA-MIP/hal-04627347v1) written by Iryna De Albuquerque Silva, Thomas Carle, Adrien Gauffriau and Claire Pagetti)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create an ACETONE CodeGenerator from the model\n",
    "indirect_gemm_generator = CodeGenerator(\n",
    "    file=model,\n",
    "    function_name=function_name,\n",
    "    external_input=True,\n",
    "    versions={\"Conv2D\":\"indirect_gemm_nn\"},\n",
    "    nb_tests=nb_tests,\n",
    "    verbose=False,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "indirect_gemm_generator.generate_c_files(indirect_gemm_output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile and run those generated code to ensure that the semantic was indeed preserved."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_6loops all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_6loops/demo_lenet ./demo_lenet_6loops/output_c.txt ./lenet_inputs.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_std_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_std_gemm/demo_lenet ./demo_lenet_std_gemm/output_c.txt ./lenet_inputs.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compiling the code\n",
    "! make -C demo_lenet_indirect_gemm all\n",
    "\n",
    "# Running the executable\n",
    "! ./demo_lenet_indirect_gemm/demo_lenet ./demo_lenet_indirect_gemm/output_c.txt ./lenet_inputs.txt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cli_compare(reference_file=(indirect_gemm_output_path / \"output_c.txt\"), c_file=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "loops_output = extract_outputs_c(path_to_output=(loops_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "std_gemm_output = extract_outputs_c(path_to_output=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "indirect_gemm_output = extract_outputs_c(path_to_output=(indirect_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "\n",
    "loops_labels = loops_output.argmax(axis = -1)\n",
    "std_gemm_labels = std_gemm_output.argmax(axis = -1)\n",
    "indirect_gemm_labels = indirect_gemm_output.argmax(axis = -1)\n",
    "\n",
    "\n",
    "print(\"Labels given by the inference:\")\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(inputs[i*nb_col+j], cmap=\"gray\")\n",
    "        print(f\"sample at position ({i},{j}) : \")\n",
    "        print(f\"    keras :         {keras_labels[i*nb_col+j]}\")\n",
    "        print(f\"    6loops :        {loops_labels[i*nb_col + j]}\")\n",
    "        print(f\"    std_gemm :      {std_gemm_labels[i*nb_col + j]}\")\n",
    "        print(f\"    indirect_gemm : {indirect_gemm_labels[i*nb_col + j]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated code gives indeed the same label for all the implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing a bit more\n",
    "\n",
    "Let's now try with several set of inputs from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Selecting new inputs\n",
    "indexes = np.random.permutation(len(x_test))[:nb_samples]\n",
    "inputs = x_test[indexes]\n",
    "write_input(inputs, nb_samples, dataset)\n",
    "\n",
    "# Keras inference and labels\n",
    "keras_outputs = model.predict(inputs)\n",
    "keras_labels = keras_outputs.argmax(axis=-1)\n",
    "\n",
    "# ACETONE's inference with the 3 versions\n",
    "! ./demo_lenet_6loops/demo_lenet ./demo_lenet_6loops/output_c.txt ./lenet_inputs.txt\n",
    "! ./demo_lenet_std_gemm/demo_lenet ./demo_lenet_std_gemm/output_c.txt ./lenet_inputs.txt\n",
    "! ./demo_lenet_indirect_gemm/demo_lenet ./demo_lenet_indirect_gemm/output_c.txt ./lenet_inputs.txt\n",
    "\n",
    "# Extracting the scores\n",
    "loops_output = extract_outputs_c(path_to_output=(loops_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "std_gemm_output = extract_outputs_c(path_to_output=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "indirect_gemm_output = extract_outputs_c(path_to_output=(indirect_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "\n",
    "# Getting the labels\n",
    "loops_labels = loops_output.argmax(axis = -1)\n",
    "std_gemm_labels = std_gemm_output.argmax(axis = -1)\n",
    "indirect_gemm_labels = indirect_gemm_output.argmax(axis = -1)\n",
    "\n",
    "# Comparing the results\n",
    "max_rel_error = 0.0\n",
    "max_abs_error = 0.0\n",
    "for i in range(nb_samples):\n",
    "    for k in range(10):\n",
    "        diff = abs(keras_outputs[i,k] - loops_output[i,k])\n",
    "        norm = abs(keras_outputs[i,k]) + abs(loops_output[i,k])\n",
    "        max_abs_error = max(max_abs_error , diff)\n",
    "        if norm != 0:\n",
    "            max_rel_error = max(max_rel_error, diff/(norm/2))\n",
    "\n",
    "print(\"Difference between loops implementation and standard gemm implementation:\")\n",
    "cli_compare(reference_file=(loops_output_path / \"output_c.txt\"), c_file=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "print(\"Difference between indirect gemm implementation and standard gemm implementation:\")\n",
    "cli_compare(reference_file=(indirect_gemm_output_path / \"output_c.txt\"), c_file=(std_gemm_output_path / \"output_c.txt\"), nb_tests=nb_tests)\n",
    "\n",
    "print(\"Comparing Keras and ACETONE's results :\")\n",
    "print(\"Maximal absolute error between them : \",max_abs_error)\n",
    "print(\"Maximal relative error between them : \",max_rel_error)\n",
    "\n",
    "fig,axs = plt.subplots(nb_row,nb_col)\n",
    "fig.suptitle(\"Label given by : Keras-6loops-std_gemm-indirect_gemm\")\n",
    "for i in range(nb_row):\n",
    "    for j in range(nb_col):\n",
    "        ax = axs[i,j]\n",
    "        ax.imshow(inputs[i*nb_col+j], cmap=\"gray\")\n",
    "        ax.set_title(f\"{keras_labels[i*nb_col+j]}-{loops_labels[i*nb_col+j]}-{std_gemm_labels[i*nb_col+j]}-{indirect_gemm_labels[i*nb_col+j]}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four labels are the same, the semantic is preserved !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
