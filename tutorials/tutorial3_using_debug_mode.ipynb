{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f0574f",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #3\n",
    "**Using the debug mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e39cfa",
   "metadata": {},
   "source": [
    "When developping new functionnalities (adding non-existents layers, changing/adding implementations, ...), it is quite common to do a first draft, try it, encounter somme bugs, debug the code, try again, find other bugs, debug again, ... and so on. The fact that we need to debug the code means we need to find where the bugs occur first.\n",
    "\n",
    "But, for ACETONE, using the framework as we are used to is not really helpful. Indeed, the framework's generated C code (and the python's inference model)  only returns the models output, leaving us no way of knowing whether the error occurred in the first layers, or in the later ones. This behaviour has led to the framework's `debug_mode`, which we will use and explain in this notebook.\n",
    "\n",
    "The first part is dedicated to generating the code, while the second part tackles the generation of a reference known to be true and the comparison with said reference.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774139e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Installs on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd25e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "\n",
    "# Path to the example files\n",
    "PATH_DIR = Path(\"../tests/models/squeezenet1\")\n",
    "\n",
    "# Path to generated directories\n",
    "output_path = Path(\"demo_squeezenet\")\n",
    "study_case_path = Path(\"study_case_squeezenet\")\n",
    "\n",
    "files_directories = [output_path, study_case_path]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            if not (directory / file).is_dir():\n",
    "                remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6046ec",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as example the model `SqueezeNet 1.0` (with `opset-version==12`) given in [*ONNX's model zoo*](https://github.com/onnx/models?tab=readme-ov-file). The beginning of the model is illustrated below.\n",
    "\n",
    "![squeezenet](./data/squeezenet1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "\n",
    "from acetone_nnet import CodeGenerator, conv2d_factory\n",
    "from acetone_nnet import debug\n",
    "from acetone_nnet.generator import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH_DIR / \"squeezenet1.onnx\"\n",
    "test_dataset = np.float32(rd.random((1,3,224,224)))\n",
    "function_name = \"demo_squeezenet\"\n",
    "nb_tests = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabe3ee",
   "metadata": {},
   "source": [
    "## Generating the code\n",
    "\n",
    "We first instantiate a `CodeGenerator` element with the debug parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging an onnx model\n",
    "debug_mode = \"onnx\"\n",
    "\n",
    "debug_generator = CodeGenerator(file=model_path,\n",
    "                                test_dataset=test_dataset,\n",
    "                                function_name=function_name,\n",
    "                                nb_tests=nb_tests,\n",
    "                                debug_mode=debug_mode)\n",
    "\n",
    "\n",
    "debug_generator.generate_c_files(output_path)\n",
    "outputs_python, targets_python = debug_generator.compute_inference(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e1945",
   "metadata": {},
   "source": [
    "Unlike in the \"classic\" mode, the  function `compute_inference` returns two elements. The first one, `outputs_python`, is a list regrouping the outputs of all the layers of interest, while the other one, `targets_python`, is a list containing the name and indice of the layer. Both lists are constructed such as `outputs_python[i]` is the output of the layer `targets_python[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make -C demo_squeezenet all\n",
    "! ./demo_squeezenet/demo_squeezenet ./demo_squeezenet/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796da46",
   "metadata": {},
   "source": [
    "After compilating the code and running the newly created executable, another text file as been created : [debug_file.txt](./demo_squeezenet/debug_file.txt). This document contains both the name and indice of each layers (on odd ligns) and the ouput of those layers (on even ligns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aea41b",
   "metadata": {},
   "source": [
    "## Formatting ACETONE's outputs\n",
    "\n",
    "After the parsing stage of ACETONE, a sorting algorithm is applied to the extracted list of layers, to ensure that they are weel ordered (no parent layer is after a child layer). This sorting stage allows us to work with the layers without worrying about wether all the inputs have been computed, or if we need to wait for another layer. But it has the inconvenience of changing the order of the layers from the original one in the model, thus requiring a sort on `outputs_python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file_path = output_path / \"debug_file.txt\"\n",
    "\n",
    "# Retrieving C's ouptut\n",
    "outputs_c, targets_c = debug.extract_outputs_c(path_to_output=debug_file_path,\n",
    "                                               data_type=debug_generator.data_type,\n",
    "                                               nb_targets=len(debug_generator.debug_target))\n",
    "# Ordering python's output\n",
    "outputs_python, targets_python = debug.reorder_outputs(outputs_python, targets_python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0594f41",
   "metadata": {},
   "source": [
    "## Generating a reference\n",
    "\n",
    "Once ACETONE's ouptut have been computed and formatted, we need a base reference to check if and when an error occurred during the inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = True\n",
    "saving_path = output_path / \"debug_squeezenet.onnx\"\n",
    "otpimize_inputs = True\n",
    "\n",
    "model, _, outputs_onnx = debug.debug_onnx(target_model=str(model_path),\n",
    "                                          dataset=test_dataset,\n",
    "                                          otpimize_inputs=otpimize_inputs,\n",
    "                                          to_save=to_save,\n",
    "                                          path=saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e8c0c",
   "metadata": {},
   "source": [
    "The `debug_onnx` function takes the model, modifies it for our problem, then runs the inference using the given dataset. The modified model, as illustrated below, as outputs after each layer having an equivalent in ACETONE. For example, the framework merges the activation layers to its parent layer, and thus, in the debug model, there is no outputs between a convolution layer and a relu.\n",
    "\n",
    "![debug_squeezenet](./data/debug_squeezenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf30a39",
   "metadata": {},
   "source": [
    "## Comparing the outputs\n",
    "\n",
    "We now can use our reference to check the framework's outputs, and locate, if they exists, errors in the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_python,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result c with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result c\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_python,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba9d1e",
   "metadata": {},
   "source": [
    "Even thought the error on the model's global output is below our threshold, a few intermediaries layers' outputs raises an error for the systems. We then have to check them, and validate or no each and every one of them to ensure that our code is up to the desired standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ae046",
   "metadata": {},
   "source": [
    "## Study case with a defective layer\n",
    "\n",
    "Let's now try to use the optimal layer definned in [tutorial2](./tutorial2_using_variants.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new implementation and adding it to ACETONE\n",
    "class Conv2D_Demo(Conv2D):\n",
    "\n",
    "    def __init__(self, **kwargs: int) -> None:\n",
    "        \"\"\"Build a Convolution layer with a demo implementation.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def generate_inference_code_layer(self) -> str:\n",
    "        \"\"\"Generate computation code for layer.\"\"\"\n",
    "        input_str = [prev_layer.output_str for prev_layer in self.previous_layer]\n",
    "        ouptut_str = f\"output_{self.path}\"\n",
    "\n",
    "        code_str =  f\"    // {self.name}_{self.idx}\\n    for (k = 0; k < {self.size}; ++k) {ouptut_str}[k] = 0.42;\"\n",
    "        return code_str\n",
    "    \n",
    "    def forward_path_layer(self, input_array) -> np.ndarray:\n",
    "        return 0.42*np.ones((1,self.output_channels,self.output_height,self.output_width))\n",
    "\n",
    "def conv2d_demo_implementation(\n",
    "        old_layer: Conv2D,\n",
    "        conv_algo: str,\n",
    ") -> Conv2D_Demo:\n",
    "    return Conv2D_Demo(\n",
    "        idx=old_layer.idx,\n",
    "        conv_algorithm=conv_algo,\n",
    "        size=old_layer.size,\n",
    "        padding=old_layer.padding,\n",
    "        strides=old_layer.strides,\n",
    "        kernel_h=old_layer.kernel_h,\n",
    "        kernel_w=old_layer.kernel_w,\n",
    "        dilation_rate=old_layer.dilation_rate,\n",
    "        nb_filters=old_layer.nb_filters,\n",
    "        input_shape=[1, old_layer.input_channels, old_layer.input_height, old_layer.input_width],\n",
    "        output_shape=[1, old_layer.output_channels, old_layer.output_height, old_layer.output_width],\n",
    "        weights=old_layer.weights,\n",
    "        biases=old_layer.biases,\n",
    "        activation_function=old_layer.activation_function,\n",
    "    )\n",
    "\n",
    "conv2d_factory.register_implementation(\"demo\", conv2d_demo_implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd0825",
   "metadata": {},
   "source": [
    "Let's change the implementation of a convolution, let's say the one at indice 29, and observe the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff808074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the C code\n",
    "debug_generator = CodeGenerator(file=model_path,\n",
    "                                test_dataset=test_dataset,\n",
    "                                function_name=function_name,\n",
    "                                nb_tests=nb_tests,\n",
    "                                debug_mode=debug_mode,\n",
    "                                versions={29:\"demo\"})\n",
    "\n",
    "\n",
    "debug_generator.generate_c_files(study_case_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0baa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the inference\n",
    "! make -C study_case_squeezenet all\n",
    "! ./study_case_squeezenet/demo_squeezenet ./study_case_squeezenet/output_c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file_path = study_case_path / \"debug_file.txt\"\n",
    "outputs_c, targets_c = debug.extract_outputs_c(path_to_output=debug_file_path,\n",
    "                                               data_type=debug_generator.data_type,\n",
    "                                               nb_targets=len(debug_generator.debug_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09576519",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f89649",
   "metadata": {},
   "source": [
    "We can see that, starting from the layer Conv2D_29, all the layers raises an error, precisely locating the error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
