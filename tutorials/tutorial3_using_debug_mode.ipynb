{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f0574f",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #3\n",
    "**Using the debug mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e39cfa",
   "metadata": {},
   "source": [
    "When developping new functionnalities (adding non-existents layers, changing/adding implementations, ...), it is quite common to do a first draft, try it, encounter somme bugs, debug the code, try again, find other bugs, debug again, ... and so on. The fact that we need to debug the code means we need to find where the bugs occur first.\n",
    "\n",
    "But, for ACETONE, using the framework as we are used to is not really helpful. Indeed, the framework's generated C code (and the python's inference model)  only returns the models output, leaving us no way of knowing whether the error occurred in the first layers, or in the later ones. This behaviour has led to the framework's `debug_mode`, which we will use and explain in this notebook.\n",
    "\n",
    "The first part is dedicated to generating the code, while the second part tackles the generation of a reference known to be true and the comparison with said reference.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774139e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Installs on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd25e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "\n",
    "# Path to the example files\n",
    "PATH_DIR = Path(\"../tests/models/squeezenet1\")\n",
    "\n",
    "# Path to generated directories\n",
    "output_path = Path(\"demo_squeezenet\")\n",
    "study_case_path = Path(\"study_case_squeezenet\")\n",
    "\n",
    "files_directories = [output_path, study_case_path]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            if not (directory / file).is_dir():\n",
    "                remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6046ec",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as example the model `SqueezeNet 1.0` (with `opset-version==12`) given in [*ONNX's model zoo*](https://github.com/onnx/models?tab=readme-ov-file). The beginning of the model is illustrated below.\n",
    "\n",
    "![squeezenet](./data/squeezenet1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eternal imports\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import pystache\n",
    "\n",
    "# ACETONE's imports\n",
    "from acetone_nnet import CodeGenerator, conv2d_factory\n",
    "from acetone_nnet import debug\n",
    "from acetone_nnet.generator import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = PATH_DIR / \"squeezenet1.onnx\"\n",
    "test_dataset = np.float32(rd.random((1,3,224,224)))\n",
    "function_name = \"demo_squeezenet\"\n",
    "nb_tests = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabe3ee",
   "metadata": {},
   "source": [
    "## Generating the code\n",
    "\n",
    "We first instantiate a `CodeGenerator` element with the debug parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging an onnx model\n",
    "debug_mode = \"onnx\"\n",
    "\n",
    "debug_generator = CodeGenerator(file=model_path,\n",
    "                                test_dataset=test_dataset,\n",
    "                                function_name=function_name,\n",
    "                                nb_tests=nb_tests,\n",
    "                                debug_mode=debug_mode)\n",
    "\n",
    "\n",
    "debug_generator.generate_c_files(output_path)\n",
    "outputs_python, targets_python = debug_generator.compute_inference(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e1945",
   "metadata": {},
   "source": [
    "Unlike in the \"classic\" mode, the  function `compute_inference` returns two elements. The first one, `outputs_python`, is a list regrouping the outputs of all the layers of interest, while the other one, `targets_python`, is a list containing the name and indice of the layer. Both lists are constructed such as `outputs_python[i]` is the output of the layer `targets_python[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make -C demo_squeezenet all\n",
    "! ./demo_squeezenet/demo_squeezenet ./demo_squeezenet/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796da46",
   "metadata": {},
   "source": [
    "After compilating the code and running the newly created executable, another text file as been created : [debug_file.txt](./demo_squeezenet/debug_file.txt). This document contains both the name and indice of each layers (on odd ligns) and the ouput of those layers (on even ligns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aea41b",
   "metadata": {},
   "source": [
    "## Formatting ACETONE's outputs\n",
    "\n",
    "After the parsing stage of ACETONE, a sorting algorithm is applied to the extracted list of layers, to ensure that they are weel ordered (no parent layer is after a child layer). This sorting stage allows us to work with the layers without worrying about wether all the inputs have been computed, or if we need to wait for another layer. But it has the inconvenience of changing the order of the layers from the original one in the model, thus requiring a sort on `outputs_python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file_path = output_path / \"debug_file.txt\"\n",
    "\n",
    "# Retrieving C's ouptut\n",
    "outputs_c, targets_c = debug.extract_outputs_c(path_to_output=debug_file_path,\n",
    "                                               data_type=debug_generator.data_type,\n",
    "                                               nb_targets=len(debug_generator.debug_target))\n",
    "# Ordering python's output\n",
    "outputs_python, targets_python = debug.reorder_outputs(outputs_python, targets_python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0594f41",
   "metadata": {},
   "source": [
    "## Generating a reference\n",
    "\n",
    "Once ACETONE's ouptut have been computed and formatted, we need a base reference to check if and when an error occurred during the inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = True\n",
    "saving_path = output_path / \"debug_squeezenet.onnx\"\n",
    "otpimize_inputs = True\n",
    "\n",
    "model, _, outputs_onnx = debug.debug_onnx(target_model=str(model_path),\n",
    "                                          dataset=test_dataset,\n",
    "                                          otpimize_inputs=otpimize_inputs,\n",
    "                                          to_save=to_save,\n",
    "                                          path=saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e8c0c",
   "metadata": {},
   "source": [
    "The `debug_onnx` function takes the model, modifies it for our problem, then runs the inference using the given dataset. The modified model, as illustrated below, as outputs after each layer having an equivalent in ACETONE. For example, the framework merges the activation layers to its parent layer, and thus, in the debug model, there is no outputs between a convolution layer and a relu.\n",
    "\n",
    "![debug_squeezenet](./data/debug_squeezenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf30a39",
   "metadata": {},
   "source": [
    "## Comparing the outputs\n",
    "\n",
    "We now can use our reference to check the framework's outputs, and locate, if they exists, errors in the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e30235df6e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute error tolerance\n",
    "atol = 5e-06\n",
    "# Relative error tolerance\n",
    "rtol = 5e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_python,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True,\n",
    "                            atol=atol,\n",
    "                            rtol=rtol,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result c with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True,\n",
    "                            atol=atol,\n",
    "                            rtol=rtol,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result c\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_python,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True,\n",
    "                            atol=atol,\n",
    "                            rtol=rtol,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fba9d1e",
   "metadata": {},
   "source": [
    "Even thought the error on the model's global output is below our threshold, a few intermediaries layers' outputs raises an error for the systems. We then have to check them, and validate or no each and every one of them to ensure that our code is up to the desired standards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
