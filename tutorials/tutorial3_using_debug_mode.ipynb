{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f0574f",
   "metadata": {},
   "source": [
    "# ACETONE tutorial #3\n",
    "**Using the debug mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e39cfa",
   "metadata": {},
   "source": [
    "When developping new functionnalities (adding non-existents layers, changing/adding implementations, ...), it is quite common to do a first draft, try it, encounter somme bugs, bedug the code, try again, find other bugs, debug again, ... and so on. The fact that we need to debug the code means we need to find where the bugs occur first.\n",
    "\n",
    "But, for ACETONE, using the framework as we are used to is not really helpful. Indeed, the framework's generated C code (and the python's inference model)  only returns the models output, leaving us no way of knowing whether the error occured in the first layers, or in the later ones. This behaviour has led to the framework's `debug_mode`, which we will use and explain in this notebook.\n",
    "\n",
    "The first part is dedicated to generating the code, while the second part tackles the generation of a reference known to be true and the comparison with said reference.\n",
    "\n",
    "* When running this notebook on Colab, we need to install ACETONE \n",
    "* If you run this notebook locally, run it in the environment in which you installed ACETONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774139e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Installs on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd25e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the working environment\n",
    "from pathlib import Path\n",
    "from os import remove, listdir\n",
    "files_directories = [Path(\"demo_squeezenet\")]\n",
    "\n",
    "for directory in files_directories:\n",
    "    if directory.exists():\n",
    "        for file in listdir(directory):\n",
    "            remove(directory / file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6046ec",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this notebook, we'll use as example the model `SqueezeNet 1.0` (with `opset-version==12`) given in [*ONNX's model zoo*](https://github.com/onnx/models?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579372c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "\n",
    "from acetone_nnet import CodeGenerator\n",
    "from acetone_nnet import debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../tests/models/squeezenet1/squeezenet1.onnx\"\n",
    "test_dataset = np.float32(rd.random((1,3,224,224)))\n",
    "function_name = \"demo_squeezenet\"\n",
    "nb_tests = 1\n",
    "\n",
    "output_path = \"demo_squeezenet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabe3ee",
   "metadata": {},
   "source": [
    "## Generating the code\n",
    "\n",
    "We first instantiate a `CodeGenerator` element with the debug parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging an onnx model\n",
    "debug_mode = \"onnx\"\n",
    "\n",
    "debug_generator = CodeGenerator(file=model_path,\n",
    "                                test_dataset=test_dataset,\n",
    "                                function_name=function_name,\n",
    "                                nb_tests=nb_tests,\n",
    "                                debug_mode=debug_mode)\n",
    "\n",
    "\n",
    "debug_generator.generate_c_files(output_path)\n",
    "outputs_python, targets_python = debug_generator.compute_inference(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e1945",
   "metadata": {},
   "source": [
    "Unlike in the \"classic\" mode, the  function `compute_inference` returns two elements. The first one, `outputs_python`, is a list regrouping the outputs of all the layers of interest, while the other one, `targets_python`, is a list containing the name and indice of the layer. Both lists are constructed such as `outputs_python[i]` is the output of the layer `targets_python[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "! make -C demo_squeezenet all\n",
    "! ./demo_squeezenet/demo_squeezenet ./demo_squeezenet/output_c.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796da46",
   "metadata": {},
   "source": [
    "After compilating the code and running the newly created executable, another text file as been created : [debug_file.txt](./demo_squeezenet/debug_file.txt). This document contains both the name and indice of each layers (on odd ligns) and the ouput of those layers (on even ligns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aea41b",
   "metadata": {},
   "source": [
    "## Formatting ACETONE's outputs\n",
    "\n",
    "After the parsing stage of ACETONE, a sorting algorithm is applied to the extracted list of layers, to ensure that they are weel ordered (no parent layer is after a child layer). This sorting stage allows us to work with the layers without worrying about wether all the inputs have been computed, or if we need to wait for another layer. But it has the inconvenience of changing the order of the layers from the original one in the model, thus requiring a sort on `outputs_python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file_path = output_path + \"/debug_file.txt\"\n",
    "\n",
    "# Retrieving C's ouptut\n",
    "outputs_c, targets_c = debug.extract_outputs_c(path_to_output=debug_file_path,\n",
    "                                               data_type=debug_generator.data_type,\n",
    "                                               nb_targets=len(debug_generator.debug_target))\n",
    "# Ordering python's output\n",
    "outputs_python, targets_python = debug.reorder_outputs(outputs_python, targets_python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0594f41",
   "metadata": {},
   "source": [
    "## Generating a reference\n",
    "\n",
    "Once ACETONE's ouptut have been computed and formatted, we need a base reference to check if and when an error occured during the inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = True\n",
    "saving_path = output_path + \"/debug_squeezenet.onnx\"\n",
    "otpimize_inputs = True\n",
    "\n",
    "model, _, outputs_onnx = debug.debug_onnx(target_model=model_path,\n",
    "                                          dataset=test_dataset,\n",
    "                                          otpimize_inputs=otpimize_inputs,\n",
    "                                          to_save=to_save,\n",
    "                                          path=saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e8c0c",
   "metadata": {},
   "source": [
    "The `debug_onnx` function takes the model, modifies it for our problem (by adding ouptuts after the layers of interest), then runs the inference using the given dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf30a39",
   "metadata": {},
   "source": [
    "## Comparing the outputs\n",
    "\n",
    "We now can use our reference to check the framework's outputs, and locate, if they exists, errors in the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_python,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result c with the result onnx\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_onnx,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the result python with the result c\n",
    "same = debug.compare_result(acetone_result=outputs_c,\n",
    "                            reference_result=outputs_python,\n",
    "                            targets=targets_python,\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406739fa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
